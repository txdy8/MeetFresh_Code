{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.review_data import *\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction._stop_words import ENGLISH_STOP_WORDS\n",
    "from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import FreqDist\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA based on reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_cloud_graph(review):\n",
    "    my_stop_words = set(stopwords.words('english') + list(ENGLISH_STOP_WORDS) + \n",
    "                    ['super', 'place','meet', 'fresh','desserts','dessert'])\n",
    "    review_text = \" \".join(reviews)\n",
    "    wordcloud = WordCloud(background_color='white', stopwords=my_stop_words).generate(review_text)\n",
    "\n",
    "    # Display the generated image:\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_20_keywords():\n",
    "    lower_full_text = review_text.lower()\n",
    "    word_tokens = word_tokenize(lower_full_text)\n",
    "    tokens = list()\n",
    "    for word in word_tokens:\n",
    "        if word.isalpha() and word not in my_stop_words:\n",
    "            tokens.append(word)\n",
    "    token_dist = FreqDist(tokens)\n",
    "    dist = pd.DataFrame(token_dist.most_common(20),columns=['Word', 'Frequency'])\n",
    "    dist.plot.barh(x='Word', y='Frequency',figsize = (10,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_20_bigram():\n",
    "    vect = CountVectorizer(stop_words=my_stop_words, ngram_range=(2,2))\n",
    "    bigrams = vect.fit_transform(review_df['review'])\n",
    "    bigram_df = pd.DataFrame(bigrams.toarray(), columns=vect.get_feature_names())\n",
    "    bigram_frequency = pd.DataFrame(bigram_df.sum(axis=0)).reset_index()\n",
    "    bigram_frequency.columns = ['bigram', 'frequency']\n",
    "    bigram_frequency = bigram_frequency.sort_values(by='frequency', ascending=False).head(20)\n",
    "    bigram_frequency.plot.barh(x='bigram', y='frequency',figsize = (10,8))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA based on geo location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_geo_graph(csv_file):\n",
    "    position = pd.read_csv(csv_file, index_col=0)\n",
    "    world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "    us_map = world[world.name == 'United States of America']\n",
    "    us_map.plot(alpha = 0.2, figsize=(15, 15))\n",
    "\n",
    "    plt.scatter(data=rest_info, x='longitude' ,y='latitude' ,c='avg_note', cmap='Greens', s=\"nb_comments\")\n",
    "    plt.colorbar()\n",
    "    plt.title('Average note of restaurants')\n",
    "    plt.xlim(-130, -65)\n",
    "    plt.ylim(23, 52)\n",
    "\n",
    "    #plt.savefig('Price To Income Ratio.jpg', dpi=600)\n",
    "\n",
    "    plt.style.use('ggplot')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
